<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="M Mubashar Ashraf">
<meta name="dcterms.date" content="2023-11-24">

<title>Machine learning - 2. Probability Theory and Random Variables</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../posts/3.0 Clustering/index.html" rel="next">
<link href="../../posts/1.0 Machine Learning Introduction/index.html" rel="prev">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Machine learning - 2. Probability Theory and Random Variables">
<meta property="og:description" content="">
<meta property="og:image" content="P.jpg">
<meta property="og:site-name" content="Machine learning">
<meta name="twitter:title" content="Machine learning - 2. Probability Theory and Random Variables">
<meta name="twitter:description" content="">
<meta name="twitter:image" content="P.jpg">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-sidebar docked nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Machine learning</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link active" href="../../about.html" rel="" target="" aria-current="page">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/Mubashar97" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/Mubashar97/Intro-ML-Basics" rel="" target=""><i class="bi bi-house" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/mmubashar/" rel="" target=""><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../posts/1.0 Machine Learning Introduction/index.html">Posts</a></li><li class="breadcrumb-item"><a href="../../posts/2.0 Probability Theory and Random Variables/index.html">2. Probability Theory and Random Variables</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title">2. Probability Theory and Random Variables</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
                                <div class="quarto-categories">
                <div class="quarto-category">Probability Theory</div>
                <div class="quarto-category">Random Variables</div>
                <div class="quarto-category">ML</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>M Mubashar Ashraf </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">November 24, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../about.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Posts</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/1.0 Machine Learning Introduction/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1. Machine Learning Introduction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/2.0 Probability Theory and Random Variables/index.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">2. Probability Theory and Random Variables</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/3.0 Clustering/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3. Clustering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/4.0 Linear and non-linear regression/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4. Linear and Non-Linear Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/5.0 Classification/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5. Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/6.0 Anomaly Outlier detection/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">6. Anomaly Outlier Detection</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="2">
    <h2 id="toc-title">On this page</h2>
   
  <ul class="collapse">
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><strong>Introduction:</strong></a></li>
  <li><a href="#mathematical-explanation" id="toc-mathematical-explanation" class="nav-link" data-scroll-target="#mathematical-explanation">Mathematical Explanation:</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion"><strong>Conclusion:</strong></a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/Mubashar97/Intro-ML-Basics/blob/main/posts/2.0 Probability Theory and Random Variables/index.qmd" class="toc-action">View source</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction"><strong>Introduction:</strong></h2>
<p>Probability Theory and Random Variables stand as pivotal concepts at the intersection of mathematics and statistics, offering a robust framework for navigating uncertainty and variability. At its core, Probability Theory provides a systematic approach to quantifying the likelihood of different outcomes in a given situation. This mathematical discipline is not confined to abstract calculations but serves as a cornerstone in statistics, underpinning methodologies that enable informed decision-making and predictive modeling.</p>
<p>The influence of Probability Theory and Random Variables transcends disciplinary boundaries, finding application in diverse fields such as data science, finance, and engineering. The significance of these concepts becomes particularly evident when delving into their role in modeling real-world phenomena. Random Variables introduce an essential element of unpredictability, allowing mathematical models to capture the inherent variability observed in natural and engineered systems. This comprehensive exploration seeks to unravel the foundational principles of Probability Theory, emphasizing the practical importance of Random Variables in tackling the intricacies of uncertainty across various domains. Through this exploration, a deeper understanding of probabilistic reasoning and its applicability to diverse scenarios is fostered, contributing to the toolkit of professionals in fields where uncertainty prevails.</p>
<section id="probability-theory-a-foundation-for-uncertainty" class="level3">
<h3 class="anchored" data-anchor-id="probability-theory-a-foundation-for-uncertainty"><strong>Probability Theory: A Foundation for Uncertainty:</strong></h3>
<p>At its core, Probability Theory is a mathematical framework that quantifies uncertainty. It provides us with a systematic way to model and analyze random events and uncertain outcomes. The theory rests on the concept of a sample space, representing all possible outcomes of a random experiment, and events, which are subsets of the sample space.</p>
<ul>
<li><strong>Probability Basics:</strong> Probability is expressed as a number between 0 and 1, where 0 indicates impossibility, 1 denotes certainty, and values in between represent degrees of likelihood. The probability of an event A is denoted as P(A).</li>
</ul>
<div class="cell" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Tossing a fair coin</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>outcomes <span class="op">=</span> [<span class="st">'Heads'</span>, <span class="st">'Tails'</span>]</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>probabilities <span class="op">=</span> [<span class="fl">0.5</span>, <span class="fl">0.5</span>]</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>plt.bar(outcomes, probabilities, color<span class="op">=</span>[<span class="st">'blue'</span>, <span class="st">'orange'</span>])</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Probability Distribution of a Fair Coin'</span>)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Outcome'</span>)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Probability'</span>)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-2-output-1.png" width="589" height="449"></p>
</div>
</div>
<ul>
<li><strong>Probability Rules:</strong> Probability Theory is governed by fundamental rules such as the addition rule (P(A ∪ B) = P(A) + P(B) - P(A ∩ B)) and the multiplication rule (P(A ∩ B) = P(A) * P(B|A)), guiding the computation of probabilities for combined events.</li>
</ul>
</section>
<section id="random-variables-bridging-theory-and-reality" class="level3">
<h3 class="anchored" data-anchor-id="random-variables-bridging-theory-and-reality"><strong>Random Variables: Bridging Theory and Reality:</strong></h3>
<p>Random Variables provide a powerful bridge between the theoretical constructs of Probability Theory and the practical modeling of uncertain phenomena. A Random Variable is a variable whose possible values are outcomes of a random phenomenon. Let’s explore key aspects:</p>
<ul>
<li><strong>Discrete vs.&nbsp;Continuous Random Variables:</strong> Random Variables can be categorized as discrete or continuous. Discrete Random Variables take on distinct values, often integers, while continuous ones can assume any value within a specified range.</li>
</ul>
<div class="cell" data-execution_count="2">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Discrete Random Variable</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.random.choice([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>], size<span class="op">=</span><span class="dv">1000</span>, p<span class="op">=</span>[<span class="fl">0.1</span>, <span class="fl">0.2</span>, <span class="fl">0.3</span>, <span class="fl">0.2</span>, <span class="fl">0.2</span>])</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>sns.histplot(data, bins<span class="op">=</span>[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>], kde<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Probability Mass Function of a Discrete Random Variable'</span>)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Outcome'</span>)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Frequency'</span>)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-3-output-1.png" width="593" height="449"></p>
</div>
</div>
<ul>
<li><p><strong>Probability Mass Functions (PMF) and Probability Density Functions (PDF):</strong> The probability distribution of a discrete Random Variable is described by its Probability Mass Function (PMF), while a continuous Random Variable is characterized by its Probability Density Function (PDF). These functions help quantify the likelihood of different outcomes.</p></li>
<li><p><strong>Expectation and Variance:</strong> The expectation (mean) and variance of a Random Variable provide insights into its central tendency and degree of variability, crucial metrics for understanding the underlying probability distribution.</p></li>
</ul>
<div class="cell" data-execution_count="3">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Continuous Random Variable</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>data_continuous <span class="op">=</span> np.random.normal(loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span><span class="dv">1</span>, size<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>sns.histplot(data_continuous, kde<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Probability Density Function of a Continuous Random Variable'</span>)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Outcome'</span>)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Density'</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-4-output-1.png" width="593" height="449"></p>
</div>
</div>
</section>
<section id="applications-in-real-world-scenarios" class="level3">
<h3 class="anchored" data-anchor-id="applications-in-real-world-scenarios"><strong>Applications in Real-World Scenarios:</strong></h3>
<p>Probability Theory and Random Variables find extensive applications in various fields.</p>
<ul>
<li><p><strong>Finance:</strong> In finance, these concepts are instrumental in modeling asset prices, risk assessment, and portfolio optimization.</p></li>
<li><p><strong>Data Science:</strong> Probability Theory underpins statistical inference and machine learning algorithms, contributing to predictive modeling and decision-making.</p></li>
</ul>
<div class="cell" data-execution_count="4">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.stats <span class="im">as</span> stats</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Normal Distribution in Data Science</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>data_scientist_salaries <span class="op">=</span> stats.norm(loc<span class="op">=</span><span class="dv">75000</span>, scale<span class="op">=</span><span class="dv">15000</span>).rvs(<span class="dv">1000</span>)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>sns.histplot(data_scientist_salaries, kde<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Salary Distribution of Data Scientists'</span>)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Salary ($)'</span>)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Density'</span>)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-5-output-1.png" width="593" height="449"></p>
</div>
</div>
<ul>
<li><strong>Engineering:</strong> Engineers use these principles for reliability analysis, ensuring the robustness of structures and systems.</li>
</ul>
</section>
</section>
<section id="mathematical-explanation" class="level2">
<h2 class="anchored" data-anchor-id="mathematical-explanation">Mathematical Explanation:</h2>
<section id="probability-theory" class="level3">
<h3 class="anchored" data-anchor-id="probability-theory"><strong>Probability Theory:</strong></h3>
<section id="sample-space-ω" class="level4">
<h4 class="anchored" data-anchor-id="sample-space-ω">1. <strong>Sample Space (Ω):</strong></h4>
<ul>
<li>The set of all possible outcomes of a random experiment.</li>
</ul>
</section>
<section id="event-e" class="level4">
<h4 class="anchored" data-anchor-id="event-e">2. <strong>Event (E):</strong></h4>
<ul>
<li>A subset of the sample space.</li>
</ul>
</section>
<section id="probability-p" class="level4">
<h4 class="anchored" data-anchor-id="probability-p">3. <strong>Probability (P):</strong></h4>
<ul>
<li><p>Assigns a numerical value to each event, denoted by P(E)</p></li>
<li><p>Satisfies the following axioms:</p>
<ul>
<li><p><strong>Non-negativity:</strong> P(E)≥0 for any event E.</p></li>
<li><p><strong>Normalization:</strong> P(Ω)=1.</p></li>
<li><p><strong>Additivity:</strong> For mutually exclusive events E1​,E2​,…,P(E1​∪E2​∪…)=P(E1​)+P(E2​)+….</p></li>
</ul></li>
</ul>
</section>
<section id="probability-of-complementary-event" class="level4">
<h4 class="anchored" data-anchor-id="probability-of-complementary-event">4. <strong>Probability of Complementary Event:</strong></h4>
<ul>
<li>P(E′)=1−P(E), where E′ is the complement of event E.</li>
</ul>
</section>
<section id="conditional-probability" class="level4">
<h4 class="anchored" data-anchor-id="conditional-probability">5. <strong>Conditional Probability:</strong></h4>
<ul>
<li>P(A∣B)=P(B)P(A∩B)​, the probability of A given B.</li>
</ul>
</section>
<section id="independent-events" class="level4">
<h4 class="anchored" data-anchor-id="independent-events">6. <strong>Independent Events:</strong></h4>
<ul>
<li>Events A and B are independent if P(A∩B)=P(A)⋅P(B).</li>
</ul>
</section>
</section>
<section id="random-variables" class="level3">
<h3 class="anchored" data-anchor-id="random-variables"><strong>Random Variables:</strong></h3>
<section id="definition" class="level4">
<h4 class="anchored" data-anchor-id="definition">1. <strong>Definition:</strong></h4>
<ul>
<li>A function X:Ω→R that assigns a real number to each outcome in the sample space.</li>
</ul>
</section>
<section id="probability-mass-function-pmf" class="level4">
<h4 class="anchored" data-anchor-id="probability-mass-function-pmf">2. <strong>Probability Mass Function (PMF):</strong></h4>
<ul>
<li>For discrete random variables, P(X=x) is the probability that X takes the value x. P(X=x)=P({ω∈Ω:X(ω)=x})</li>
</ul>
</section>
<section id="probability-density-function-pdf" class="level4">
<h4 class="anchored" data-anchor-id="probability-density-function-pdf">3. <strong>Probability Density Function (PDF):</strong></h4>
<ul>
<li>For continuous random variables, fX​(x) such that P(a≤X≤b)=∫ab​fX​(x)dx.</li>
</ul>
</section>
<section id="cumulative-distribution-function-cdf" class="level4">
<h4 class="anchored" data-anchor-id="cumulative-distribution-function-cdf">4. <strong>Cumulative Distribution Function (CDF):</strong></h4>
<ul>
<li><p>FX​(x)=P(X≤x).</p></li>
<li><p>For discrete X: FX​(x)=∑t≤x​P(X=t).</p></li>
<li><p>For continuous X: FX​(x)=∫−∞x​fX​(t)dt.</p></li>
</ul>
</section>
<section id="expected-value-mean" class="level4">
<h4 class="anchored" data-anchor-id="expected-value-mean">5. <strong>Expected Value (Mean):</strong></h4>
<ul>
<li><p>For discrete X: E(X)=∑x​x⋅P(X=x).</p></li>
<li><p>For continuous X: E(X)=Lim(−∞,∞)∫​x⋅fX​(x)dx.</p></li>
</ul>
</section>
<section id="variance" class="level4">
<h4 class="anchored" data-anchor-id="variance">6. <strong>Variance:</strong></h4>
<ul>
<li>Var(X)=E((X−E(X))2).</li>
</ul>
<p>Probability theory and random variables provide a rigorous framework for quantifying uncertainty and analyzing the behavior of random phenomena in diverse fields.</p>
<ul>
<li>Another example from a contineous random variables is shown below,</li>
</ul>
<div class="cell" data-execution_count="5">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> norm</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a continuous random variable (e.g., normal distribution)</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>rv <span class="op">=</span> norm(loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate data points for the x-axis</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">1000</span>)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Probability Density Function (PDF)</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>pdf_values <span class="op">=</span> rv.pdf(x)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Cumulative Distribution Function (CDF)</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>cdf_values <span class="op">=</span> rv.cdf(x)</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Create subplots</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>fig, (ax1, ax2) <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">10</span>))</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Subplot 1: Probability Density Function (PDF)</span></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>ax1.plot(x, pdf_values, label<span class="op">=</span><span class="st">'PDF'</span>, color<span class="op">=</span><span class="st">'blue'</span>)</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>ax1.fill_between(x, pdf_values, alpha<span class="op">=</span><span class="fl">0.3</span>, color<span class="op">=</span><span class="st">'blue'</span>)</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="st">'Probability Density Function (PDF)'</span>)</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">'Random Variable (X)'</span>)</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">'Probability Density'</span>)</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>ax1.legend()</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Subplot 2: Cumulative Distribution Function (CDF)</span></span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>ax2.plot(x, cdf_values, label<span class="op">=</span><span class="st">'CDF'</span>, color<span class="op">=</span><span class="st">'orange'</span>)</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>ax2.set_title(<span class="st">'Cumulative Distribution Function (CDF)'</span>)</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>ax2.set_xlabel(<span class="st">'Random Variable (X)'</span>)</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="st">'Cumulative Probability'</span>)</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>ax2.legend()</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-6-output-1.png" width="758" height="950"></p>
</div>
</div>
<p>The provided Python code generates a graph illustrating fundamental concepts in probability theory for a continuous random variable. In this example, a normal distribution with a mean of 0 and a standard deviation of 1 is chosen. The code calculates the Probability Density Function (PDF) and Cumulative Distribution Function (CDF) values for this distribution. The generated data points along the x-axis allow visualization of how the probability density varies across different values of the random variable. The resulting graph is divided into two subplots: the first showcasing the PDF, representing the likelihood of observing specific values, and the second depicting the CDF, which reveals the cumulative probability up to each point. The graph is customized with titles, labels, and legends for clarity, providing a visual representation of the distribution’s characteristics. This code serves as an illustrative tool for comprehending the core concepts of probability theory through practical implementation and visualization.</p>
<ul>
<li>Below given example shows the histogram illustration for the distribution of random variables,</li>
</ul>
<div class="cell" data-execution_count="6">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> norm</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a random variable with a normal distribution</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>mean <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>std_dev <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>random_variable <span class="op">=</span> np.random.normal(mean, std_dev, <span class="dv">1000</span>)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting the histogram</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>plt.hist(random_variable, bins<span class="op">=</span><span class="dv">30</span>, density<span class="op">=</span><span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, color<span class="op">=</span><span class="st">'blue'</span>, edgecolor<span class="op">=</span><span class="st">'black'</span>)</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Overlaying the probability density function (PDF) for comparison</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>xmin, xmax <span class="op">=</span> plt.xlim()</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(xmin, xmax, <span class="dv">100</span>)</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>pdf <span class="op">=</span> norm.pdf(x, mean, std_dev)</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>plt.plot(x, pdf, <span class="st">'k'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Adding labels and title</span></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Histogram and PDF of a Random Variable'</span>)</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Random Variable Values'</span>)</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Probability Density'</span>)</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>plt.legend([<span class="st">'PDF'</span>, <span class="st">'Histogram'</span>])</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the plot</span></span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-7-output-1.png" width="589" height="449"></p>
</div>
</div>
<p>The Python code utilizes the matplotlib library to create a complex graph that visually depicts the distribution of a random variable through a histogram. In this example, a random variable is generated based on a normal distribution using NumPy’s random module. The histogram is then constructed using the matplotlib <strong><code>hist</code></strong> function, showcasing the frequency distribution of the generated random variable. The histogram is configured with 30 bins for granularity, and the transparency (alpha) is set to enhance visualization.</p>
<p>To provide additional context and comparison, the code overlays the Probability Density Function (PDF) of the normal distribution onto the histogram. This allows for a visual correlation between the empirical distribution (histogram) and the theoretical probability density. The PDF is generated using the scipy.stats module, specifically the <strong><code>norm.pdf</code></strong> function. Labels, including a title and axis labels, are added to the plot to enhance interpretability. The resulting graph provides a comprehensive visualization of the distribution of the random variable, offering insights into its probability density and variability. This type of graphical representation is widely used in probability theory and statistics to analyze and communicate the characteristics of random variables.</p>
</section>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion"><strong>Conclusion:</strong></h2>
<p>Probability Theory and Random Variables serve as the bedrock for navigating uncertainty, enabling us to make informed decisions and predictions across diverse domains. Whether unraveling the mysteries of chance or harnessing the power of statistics in practical applications, a profound understanding of these concepts is indispensable. This exploration merely scratches the surface, inviting curious minds to delve deeper into the fascinating world of probability and randomness.<br>
</p>


<!-- -->

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../posts/1.0 Machine Learning Introduction/index.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">1. Machine Learning Introduction</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../posts/3.0 Clustering/index.html" class="pagination-link">
        <span class="nav-page-text">3. Clustering</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb7" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "2\\. Probability Theory and Random Variables"</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "M Mubashar Ashraf"</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "2023-11-24"</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span><span class="co"> [Probability Theory, Random Variables, ML]</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="an">output:</span><span class="co"> html_document</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="an">image:</span><span class="co"> "P.jpg"</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="co">    code-fold: true</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="an">jupyter:</span><span class="co"> python3</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a><span class="an">code-fold:</span><span class="co"> true</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="an">keep-ipynb:</span><span class="co"> true</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a><span class="fu">## **Introduction:**</span></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>Probability Theory and Random Variables stand as pivotal concepts at the intersection of mathematics and statistics, offering a robust framework for navigating uncertainty and variability. At its core, Probability Theory provides a systematic approach to quantifying the likelihood of different outcomes in a given situation. This mathematical discipline is not confined to abstract calculations but serves as a cornerstone in statistics, underpinning methodologies that enable informed decision-making and predictive modeling.</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>The influence of Probability Theory and Random Variables transcends disciplinary boundaries, finding application in diverse fields such as data science, finance, and engineering. The significance of these concepts becomes particularly evident when delving into their role in modeling real-world phenomena. Random Variables introduce an essential element of unpredictability, allowing mathematical models to capture the inherent variability observed in natural and engineered systems. This comprehensive exploration seeks to unravel the foundational principles of Probability Theory, emphasizing the practical importance of Random Variables in tackling the intricacies of uncertainty across various domains. Through this exploration, a deeper understanding of probabilistic reasoning and its applicability to diverse scenarios is fostered, contributing to the toolkit of professionals in fields where uncertainty prevails.</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a><span class="fu">### **Probability Theory: A Foundation for Uncertainty:**</span></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>At its core, Probability Theory is a mathematical framework that quantifies uncertainty. It provides us with a systematic way to model and analyze random events and uncertain outcomes. The theory rests on the concept of a sample space, representing all possible outcomes of a random experiment, and events, which are subsets of the sample space.</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Probability Basics:** Probability is expressed as a number between 0 and 1, where 0 indicates impossibility, 1 denotes certainty, and values in between represent degrees of likelihood. The probability of an event A is denoted as P(A).</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Tossing a fair coin</span></span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>outcomes <span class="op">=</span> [<span class="st">'Heads'</span>, <span class="st">'Tails'</span>]</span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>probabilities <span class="op">=</span> [<span class="fl">0.5</span>, <span class="fl">0.5</span>]</span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a>plt.bar(outcomes, probabilities, color<span class="op">=</span>[<span class="st">'blue'</span>, <span class="st">'orange'</span>])</span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Probability Distribution of a Fair Coin'</span>)</span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Outcome'</span>)</span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Probability'</span>)</span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Probability Rules:** Probability Theory is governed by fundamental rules such as the addition rule (P(A ∪ B) = P(A) + P(B) - P(A ∩ B)) and the multiplication rule (P(A ∩ B) = P(A) <span class="sc">\*</span> P(B\|A)), guiding the computation of probabilities for combined events.</span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a><span class="fu">### **Random Variables: Bridging Theory and Reality:**</span></span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a>Random Variables provide a powerful bridge between the theoretical constructs of Probability Theory and the practical modeling of uncertain phenomena. A Random Variable is a variable whose possible values are outcomes of a random phenomenon. Let's explore key aspects:</span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-51"><a href="#cb7-51" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Discrete vs. Continuous Random Variables:** Random Variables can be categorized as discrete or continuous. Discrete Random Variables take on distinct values, often integers, while continuous ones can assume any value within a specified range.</span>
<span id="cb7-52"><a href="#cb7-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-55"><a href="#cb7-55" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb7-56"><a href="#cb7-56" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb7-57"><a href="#cb7-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-58"><a href="#cb7-58" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Discrete Random Variable</span></span>
<span id="cb7-59"><a href="#cb7-59" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.random.choice([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>], size<span class="op">=</span><span class="dv">1000</span>, p<span class="op">=</span>[<span class="fl">0.1</span>, <span class="fl">0.2</span>, <span class="fl">0.3</span>, <span class="fl">0.2</span>, <span class="fl">0.2</span>])</span>
<span id="cb7-60"><a href="#cb7-60" aria-hidden="true" tabindex="-1"></a>sns.histplot(data, bins<span class="op">=</span>[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>], kde<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb7-61"><a href="#cb7-61" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Probability Mass Function of a Discrete Random Variable'</span>)</span>
<span id="cb7-62"><a href="#cb7-62" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Outcome'</span>)</span>
<span id="cb7-63"><a href="#cb7-63" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Frequency'</span>)</span>
<span id="cb7-64"><a href="#cb7-64" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb7-65"><a href="#cb7-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-66"><a href="#cb7-66" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb7-67"><a href="#cb7-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-68"><a href="#cb7-68" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Probability Mass Functions (PMF) and Probability Density Functions (PDF):** The probability distribution of a discrete Random Variable is described by its Probability Mass Function (PMF), while a continuous Random Variable is characterized by its Probability Density Function (PDF). These functions help quantify the likelihood of different outcomes.</span>
<span id="cb7-69"><a href="#cb7-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-70"><a href="#cb7-70" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Expectation and Variance:** The expectation (mean) and variance of a Random Variable provide insights into its central tendency and degree of variability, crucial metrics for understanding the underlying probability distribution.</span>
<span id="cb7-71"><a href="#cb7-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-74"><a href="#cb7-74" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb7-75"><a href="#cb7-75" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Continuous Random Variable</span></span>
<span id="cb7-76"><a href="#cb7-76" aria-hidden="true" tabindex="-1"></a>data_continuous <span class="op">=</span> np.random.normal(loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span><span class="dv">1</span>, size<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb7-77"><a href="#cb7-77" aria-hidden="true" tabindex="-1"></a>sns.histplot(data_continuous, kde<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-78"><a href="#cb7-78" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Probability Density Function of a Continuous Random Variable'</span>)</span>
<span id="cb7-79"><a href="#cb7-79" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Outcome'</span>)</span>
<span id="cb7-80"><a href="#cb7-80" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Density'</span>)</span>
<span id="cb7-81"><a href="#cb7-81" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb7-82"><a href="#cb7-82" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb7-83"><a href="#cb7-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-84"><a href="#cb7-84" aria-hidden="true" tabindex="-1"></a><span class="fu">### **Applications in Real-World Scenarios:**</span></span>
<span id="cb7-85"><a href="#cb7-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-86"><a href="#cb7-86" aria-hidden="true" tabindex="-1"></a>Probability Theory and Random Variables find extensive applications in various fields.</span>
<span id="cb7-87"><a href="#cb7-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-88"><a href="#cb7-88" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Finance:** In finance, these concepts are instrumental in modeling asset prices, risk assessment, and portfolio optimization.</span>
<span id="cb7-89"><a href="#cb7-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-90"><a href="#cb7-90" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Data Science:** Probability Theory underpins statistical inference and machine learning algorithms, contributing to predictive modeling and decision-making.</span>
<span id="cb7-91"><a href="#cb7-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-94"><a href="#cb7-94" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb7-95"><a href="#cb7-95" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.stats <span class="im">as</span> stats</span>
<span id="cb7-96"><a href="#cb7-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-97"><a href="#cb7-97" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Normal Distribution in Data Science</span></span>
<span id="cb7-98"><a href="#cb7-98" aria-hidden="true" tabindex="-1"></a>data_scientist_salaries <span class="op">=</span> stats.norm(loc<span class="op">=</span><span class="dv">75000</span>, scale<span class="op">=</span><span class="dv">15000</span>).rvs(<span class="dv">1000</span>)</span>
<span id="cb7-99"><a href="#cb7-99" aria-hidden="true" tabindex="-1"></a>sns.histplot(data_scientist_salaries, kde<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-100"><a href="#cb7-100" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Salary Distribution of Data Scientists'</span>)</span>
<span id="cb7-101"><a href="#cb7-101" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Salary ($)'</span>)</span>
<span id="cb7-102"><a href="#cb7-102" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Density'</span>)</span>
<span id="cb7-103"><a href="#cb7-103" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb7-104"><a href="#cb7-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-105"><a href="#cb7-105" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb7-106"><a href="#cb7-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-107"><a href="#cb7-107" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Engineering:** Engineers use these principles for reliability analysis, ensuring the robustness of structures and systems.</span>
<span id="cb7-108"><a href="#cb7-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-109"><a href="#cb7-109" aria-hidden="true" tabindex="-1"></a><span class="fu">## Mathematical Explanation:</span></span>
<span id="cb7-110"><a href="#cb7-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-111"><a href="#cb7-111" aria-hidden="true" tabindex="-1"></a><span class="fu">### **Probability Theory:**</span></span>
<span id="cb7-112"><a href="#cb7-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-113"><a href="#cb7-113" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 1. **Sample Space (Ω):**</span></span>
<span id="cb7-114"><a href="#cb7-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-115"><a href="#cb7-115" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The set of all possible outcomes of a random experiment.</span>
<span id="cb7-116"><a href="#cb7-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-117"><a href="#cb7-117" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 2. **Event (E):**</span></span>
<span id="cb7-118"><a href="#cb7-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-119"><a href="#cb7-119" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>A subset of the sample space.</span>
<span id="cb7-120"><a href="#cb7-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-121"><a href="#cb7-121" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 3. **Probability (P):**</span></span>
<span id="cb7-122"><a href="#cb7-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-123"><a href="#cb7-123" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Assigns a numerical value to each event, denoted by P(E)</span>
<span id="cb7-124"><a href="#cb7-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-125"><a href="#cb7-125" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Satisfies the following axioms:</span>
<span id="cb7-126"><a href="#cb7-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-127"><a href="#cb7-127" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>**Non-negativity:** P(E)≥0 for any event E.</span>
<span id="cb7-128"><a href="#cb7-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-129"><a href="#cb7-129" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>**Normalization:** P(Ω)=1.</span>
<span id="cb7-130"><a href="#cb7-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-131"><a href="#cb7-131" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>**Additivity:** For mutually exclusive events E1​,E2​,...,P(E1​∪E2​∪...)=P(E1​)+P(E2​)+....</span>
<span id="cb7-132"><a href="#cb7-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-133"><a href="#cb7-133" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 4. **Probability of Complementary Event:**</span></span>
<span id="cb7-134"><a href="#cb7-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-135"><a href="#cb7-135" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>P(E′)=1−P(E), where E′ is the complement of event E.</span>
<span id="cb7-136"><a href="#cb7-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-137"><a href="#cb7-137" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 5. **Conditional Probability:**</span></span>
<span id="cb7-138"><a href="#cb7-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-139"><a href="#cb7-139" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>P(A∣B)=P(B)P(A∩B)​, the probability of A given B.</span>
<span id="cb7-140"><a href="#cb7-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-141"><a href="#cb7-141" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 6. **Independent Events:**</span></span>
<span id="cb7-142"><a href="#cb7-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-143"><a href="#cb7-143" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Events A and B are independent if P(A∩B)=P(A)⋅P(B).</span>
<span id="cb7-144"><a href="#cb7-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-145"><a href="#cb7-145" aria-hidden="true" tabindex="-1"></a><span class="fu">### **Random Variables:**</span></span>
<span id="cb7-146"><a href="#cb7-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-147"><a href="#cb7-147" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 1. **Definition:**</span></span>
<span id="cb7-148"><a href="#cb7-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-149"><a href="#cb7-149" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>A function X:Ω→R that assigns a real number to each outcome in the sample space.</span>
<span id="cb7-150"><a href="#cb7-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-151"><a href="#cb7-151" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 2. **Probability Mass Function (PMF):**</span></span>
<span id="cb7-152"><a href="#cb7-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-153"><a href="#cb7-153" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>For discrete random variables, P(X=x) is the probability that X takes the value x. P(X=x)=P({ω∈Ω:X(ω)=x})</span>
<span id="cb7-154"><a href="#cb7-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-155"><a href="#cb7-155" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 3. **Probability Density Function (PDF):**</span></span>
<span id="cb7-156"><a href="#cb7-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-157"><a href="#cb7-157" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>For continuous random variables, fX​(x) such that P(a≤X≤b)=∫ab​fX​(x)dx.</span>
<span id="cb7-158"><a href="#cb7-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-159"><a href="#cb7-159" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 4. **Cumulative Distribution Function (CDF):**</span></span>
<span id="cb7-160"><a href="#cb7-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-161"><a href="#cb7-161" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>FX​(x)=P(X≤x).</span>
<span id="cb7-162"><a href="#cb7-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-163"><a href="#cb7-163" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>For discrete X: FX​(x)=∑t≤x​P(X=t).</span>
<span id="cb7-164"><a href="#cb7-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-165"><a href="#cb7-165" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>For continuous X: FX​(x)=∫−∞x​fX​(t)dt.</span>
<span id="cb7-166"><a href="#cb7-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-167"><a href="#cb7-167" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 5. **Expected Value (Mean):**</span></span>
<span id="cb7-168"><a href="#cb7-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-169"><a href="#cb7-169" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>For discrete X: E(X)=∑x​x⋅P(X=x).</span>
<span id="cb7-170"><a href="#cb7-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-171"><a href="#cb7-171" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>For continuous X: E(X)=Lim(−∞,∞)∫​x⋅fX​(x)dx.</span>
<span id="cb7-172"><a href="#cb7-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-173"><a href="#cb7-173" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 6. **Variance:**</span></span>
<span id="cb7-174"><a href="#cb7-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-175"><a href="#cb7-175" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Var(X)=E((X−E(X))2).</span>
<span id="cb7-176"><a href="#cb7-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-177"><a href="#cb7-177" aria-hidden="true" tabindex="-1"></a>Probability theory and random variables provide a rigorous framework for quantifying uncertainty and analyzing the behavior of random phenomena in diverse fields.</span>
<span id="cb7-178"><a href="#cb7-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-179"><a href="#cb7-179" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Another example from a contineous random variables is shown below,</span>
<span id="cb7-180"><a href="#cb7-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-183"><a href="#cb7-183" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb7-184"><a href="#cb7-184" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb7-185"><a href="#cb7-185" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb7-186"><a href="#cb7-186" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> norm</span>
<span id="cb7-187"><a href="#cb7-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-188"><a href="#cb7-188" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a continuous random variable (e.g., normal distribution)</span></span>
<span id="cb7-189"><a href="#cb7-189" aria-hidden="true" tabindex="-1"></a>rv <span class="op">=</span> norm(loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb7-190"><a href="#cb7-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-191"><a href="#cb7-191" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate data points for the x-axis</span></span>
<span id="cb7-192"><a href="#cb7-192" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">1000</span>)</span>
<span id="cb7-193"><a href="#cb7-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-194"><a href="#cb7-194" aria-hidden="true" tabindex="-1"></a><span class="co"># Probability Density Function (PDF)</span></span>
<span id="cb7-195"><a href="#cb7-195" aria-hidden="true" tabindex="-1"></a>pdf_values <span class="op">=</span> rv.pdf(x)</span>
<span id="cb7-196"><a href="#cb7-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-197"><a href="#cb7-197" aria-hidden="true" tabindex="-1"></a><span class="co"># Cumulative Distribution Function (CDF)</span></span>
<span id="cb7-198"><a href="#cb7-198" aria-hidden="true" tabindex="-1"></a>cdf_values <span class="op">=</span> rv.cdf(x)</span>
<span id="cb7-199"><a href="#cb7-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-200"><a href="#cb7-200" aria-hidden="true" tabindex="-1"></a><span class="co"># Create subplots</span></span>
<span id="cb7-201"><a href="#cb7-201" aria-hidden="true" tabindex="-1"></a>fig, (ax1, ax2) <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">10</span>))</span>
<span id="cb7-202"><a href="#cb7-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-203"><a href="#cb7-203" aria-hidden="true" tabindex="-1"></a><span class="co"># Subplot 1: Probability Density Function (PDF)</span></span>
<span id="cb7-204"><a href="#cb7-204" aria-hidden="true" tabindex="-1"></a>ax1.plot(x, pdf_values, label<span class="op">=</span><span class="st">'PDF'</span>, color<span class="op">=</span><span class="st">'blue'</span>)</span>
<span id="cb7-205"><a href="#cb7-205" aria-hidden="true" tabindex="-1"></a>ax1.fill_between(x, pdf_values, alpha<span class="op">=</span><span class="fl">0.3</span>, color<span class="op">=</span><span class="st">'blue'</span>)</span>
<span id="cb7-206"><a href="#cb7-206" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="st">'Probability Density Function (PDF)'</span>)</span>
<span id="cb7-207"><a href="#cb7-207" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">'Random Variable (X)'</span>)</span>
<span id="cb7-208"><a href="#cb7-208" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">'Probability Density'</span>)</span>
<span id="cb7-209"><a href="#cb7-209" aria-hidden="true" tabindex="-1"></a>ax1.legend()</span>
<span id="cb7-210"><a href="#cb7-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-211"><a href="#cb7-211" aria-hidden="true" tabindex="-1"></a><span class="co"># Subplot 2: Cumulative Distribution Function (CDF)</span></span>
<span id="cb7-212"><a href="#cb7-212" aria-hidden="true" tabindex="-1"></a>ax2.plot(x, cdf_values, label<span class="op">=</span><span class="st">'CDF'</span>, color<span class="op">=</span><span class="st">'orange'</span>)</span>
<span id="cb7-213"><a href="#cb7-213" aria-hidden="true" tabindex="-1"></a>ax2.set_title(<span class="st">'Cumulative Distribution Function (CDF)'</span>)</span>
<span id="cb7-214"><a href="#cb7-214" aria-hidden="true" tabindex="-1"></a>ax2.set_xlabel(<span class="st">'Random Variable (X)'</span>)</span>
<span id="cb7-215"><a href="#cb7-215" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="st">'Cumulative Probability'</span>)</span>
<span id="cb7-216"><a href="#cb7-216" aria-hidden="true" tabindex="-1"></a>ax2.legend()</span>
<span id="cb7-217"><a href="#cb7-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-218"><a href="#cb7-218" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb7-219"><a href="#cb7-219" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb7-220"><a href="#cb7-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-221"><a href="#cb7-221" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb7-222"><a href="#cb7-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-223"><a href="#cb7-223" aria-hidden="true" tabindex="-1"></a>The provided Python code generates a graph illustrating fundamental concepts in probability theory for a continuous random variable. In this example, a normal distribution with a mean of 0 and a standard deviation of 1 is chosen. The code calculates the Probability Density Function (PDF) and Cumulative Distribution Function (CDF) values for this distribution. The generated data points along the x-axis allow visualization of how the probability density varies across different values of the random variable. The resulting graph is divided into two subplots: the first showcasing the PDF, representing the likelihood of observing specific values, and the second depicting the CDF, which reveals the cumulative probability up to each point. The graph is customized with titles, labels, and legends for clarity, providing a visual representation of the distribution's characteristics. This code serves as an illustrative tool for comprehending the core concepts of probability theory through practical implementation and visualization.</span>
<span id="cb7-224"><a href="#cb7-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-225"><a href="#cb7-225" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Below given example shows the histogram illustration for the distribution of random variables,</span>
<span id="cb7-226"><a href="#cb7-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-229"><a href="#cb7-229" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb7-230"><a href="#cb7-230" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb7-231"><a href="#cb7-231" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb7-232"><a href="#cb7-232" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> norm</span>
<span id="cb7-233"><a href="#cb7-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-234"><a href="#cb7-234" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a random variable with a normal distribution</span></span>
<span id="cb7-235"><a href="#cb7-235" aria-hidden="true" tabindex="-1"></a>mean <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb7-236"><a href="#cb7-236" aria-hidden="true" tabindex="-1"></a>std_dev <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb7-237"><a href="#cb7-237" aria-hidden="true" tabindex="-1"></a>random_variable <span class="op">=</span> np.random.normal(mean, std_dev, <span class="dv">1000</span>)</span>
<span id="cb7-238"><a href="#cb7-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-239"><a href="#cb7-239" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting the histogram</span></span>
<span id="cb7-240"><a href="#cb7-240" aria-hidden="true" tabindex="-1"></a>plt.hist(random_variable, bins<span class="op">=</span><span class="dv">30</span>, density<span class="op">=</span><span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, color<span class="op">=</span><span class="st">'blue'</span>, edgecolor<span class="op">=</span><span class="st">'black'</span>)</span>
<span id="cb7-241"><a href="#cb7-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-242"><a href="#cb7-242" aria-hidden="true" tabindex="-1"></a><span class="co"># Overlaying the probability density function (PDF) for comparison</span></span>
<span id="cb7-243"><a href="#cb7-243" aria-hidden="true" tabindex="-1"></a>xmin, xmax <span class="op">=</span> plt.xlim()</span>
<span id="cb7-244"><a href="#cb7-244" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(xmin, xmax, <span class="dv">100</span>)</span>
<span id="cb7-245"><a href="#cb7-245" aria-hidden="true" tabindex="-1"></a>pdf <span class="op">=</span> norm.pdf(x, mean, std_dev)</span>
<span id="cb7-246"><a href="#cb7-246" aria-hidden="true" tabindex="-1"></a>plt.plot(x, pdf, <span class="st">'k'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb7-247"><a href="#cb7-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-248"><a href="#cb7-248" aria-hidden="true" tabindex="-1"></a><span class="co"># Adding labels and title</span></span>
<span id="cb7-249"><a href="#cb7-249" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Histogram and PDF of a Random Variable'</span>)</span>
<span id="cb7-250"><a href="#cb7-250" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Random Variable Values'</span>)</span>
<span id="cb7-251"><a href="#cb7-251" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Probability Density'</span>)</span>
<span id="cb7-252"><a href="#cb7-252" aria-hidden="true" tabindex="-1"></a>plt.legend([<span class="st">'PDF'</span>, <span class="st">'Histogram'</span>])</span>
<span id="cb7-253"><a href="#cb7-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-254"><a href="#cb7-254" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the plot</span></span>
<span id="cb7-255"><a href="#cb7-255" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb7-256"><a href="#cb7-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-257"><a href="#cb7-257" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb7-258"><a href="#cb7-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-259"><a href="#cb7-259" aria-hidden="true" tabindex="-1"></a>The Python code utilizes the matplotlib library to create a complex graph that visually depicts the distribution of a random variable through a histogram. In this example, a random variable is generated based on a normal distribution using NumPy's random module. The histogram is then constructed using the matplotlib **`hist`** function, showcasing the frequency distribution of the generated random variable. The histogram is configured with 30 bins for granularity, and the transparency (alpha) is set to enhance visualization.</span>
<span id="cb7-260"><a href="#cb7-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-261"><a href="#cb7-261" aria-hidden="true" tabindex="-1"></a>To provide additional context and comparison, the code overlays the Probability Density Function (PDF) of the normal distribution onto the histogram. This allows for a visual correlation between the empirical distribution (histogram) and the theoretical probability density. The PDF is generated using the scipy.stats module, specifically the **`norm.pdf`** function. Labels, including a title and axis labels, are added to the plot to enhance interpretability. The resulting graph provides a comprehensive visualization of the distribution of the random variable, offering insights into its probability density and variability. This type of graphical representation is widely used in probability theory and statistics to analyze and communicate the characteristics of random variables.</span>
<span id="cb7-262"><a href="#cb7-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-263"><a href="#cb7-263" aria-hidden="true" tabindex="-1"></a><span class="fu">## **Conclusion:**</span></span>
<span id="cb7-264"><a href="#cb7-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-265"><a href="#cb7-265" aria-hidden="true" tabindex="-1"></a>Probability Theory and Random Variables serve as the bedrock for navigating uncertainty, enabling us to make informed decisions and predictions across diverse domains. Whether unraveling the mysteries of chance or harnessing the power of statistics in practical applications, a profound understanding of these concepts is indispensable. This exploration merely scratches the surface, inviting curious minds to delve deeper into the fascinating world of probability and randomness.\</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">M Mubashar</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/Mubashar97">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/mmubashar/">
      <i class="bi bi-linkedin" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>



</body></html>