{"title":"1\\. Machine Learning Introduction","markdown":{"yaml":{"title":"1\\. Machine Learning Introduction","author":"M Mubashar Ashraf","date":"2023-11-25","categories":["Machine Learing Basics"],"output":"html_document","image":"ML-Intro.jpg","format":{"html":{"code-fold":true}},"jupyter":"python3","code-fold":true,"keep-ipynb":true},"headingText":"What is Machine Learning?","containsRefs":false,"markdown":"\n\n\nMachine learning is a branch of artificial intelligence that focuses on creating algorithms and statistical models for making predictions using data.\n\n-   The fundamental procedure involves the extensive training of a model using a well-defined dataset, where the model learns intricate patterns and relationships within the provided information. This training phase is crucial, as it equips the model with the ability to generalize its acquired knowledge and apply it to new, unseen data, thereby facilitating accurate predictions.\n\n-   There are different types of ways these computer models can learn. In one method called supervised learning, the computer learns from examples where we already know the answers. In another method called unsupervised learning, it figures out patterns and relationships from data without having specific answers given to it. There's also semi-supervised learning, which is a mix of both, and reinforcement learning, where the computer learns by trying things out and getting feedback.\n\n-   So, machine learning is like giving computers the ability to learn from experience and data to make smart predictions.\n\n## Machine Learning Applications:\n\nMachine learning plays an important role in various industries including, healthcare, engineering finance etc.\n\nExamples of machine learning applications are given below,\n\n1.  **Fraud detection:** Employing machine learning algorithms aids in identifying fraudulent transactions through the analysis of patterns within transaction data.\n\n2.  **Image classification:** Machine learning algorithms can be specifically trained to categorize images based on their content, performing tasks like recognizing objects or individuals in photos.\n\n3.  **Predictive maintenance:** Leveraging machine learning algorithms enables the prediction of equipment failures, facilitating proactive maintenance and minimizing downtime.\n\n4.  **Recommender systems:** Machine learning algorithms excel in suggesting products or services based on a user's past interactions with a system, enhancing user experience and engagement.\n\n## Classification of Machine Learning\n\nML is generally classified into three main categories.\n\n### 1. Supervised Learning\n\nSupervised learning is like teaching a computer to predict things. For instance, you can use it to guess a house's price based on its size, location, and other details.Supervised learning is like teaching a computer to predict things. For instance, you can use it to guess a house's price based on its size, location, and other details.\n\n**Examples:**\n\n-   [Linear Regression]{.underline} involves forecasting a house's price by considering its square footage.\n\n-   [Logistic Regression]{.underline} is employed to predict the likelihood of an event, like whether a customer will make a purchase.\n\n-   [Decision Trees]{.underline} are used to estimate the probability of loan applicants defaulting based on their financial history.\n\n-   [Random Forest]{.underline} is applied to predict the species of an iris plant based on its physical characteristics.\n\n-   [Naive Bayes]{.underline} is utilized to determine the sentiment of a movie review, classifying it as positive, negative, or neutral.\n\nExample with code for Supervised Learning (Linear Regression)\n\n```{python}\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_diabetes\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\n# Load the Diabetes dataset\ndiabetes = load_diabetes()\ndata = diabetes.data\ntarget = diabetes.target\n\n# Select a single feature (let's use BMI - body mass index)\nX = data[:, np.newaxis, 2]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, target, test_size=0.2, random_state=42)\n\n# Initialize and train the linear regression model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred = model.predict(X_test)\n\n# Calculate Mean Squared Error\nmse = mean_squared_error(y_test, y_pred)\nprint(f'Mean Squared Error: {mse}')\n\n# Visualize the linear regression line\nplt.figure(figsize=(10, 6))\nplt.scatter(X_test.flatten(), y_test, label='Actual Values')\nplt.plot(X_test.flatten(), y_pred, color='red', linewidth=2, label='Linear Regression Line')\nplt.title('Linear Regression Example (Diabetes Dataset)')\nplt.xlabel('Body Mass Index (BMI)')\nplt.ylabel('Diabetes Progression')\nplt.legend()\nplt.show()\n```\n\n### 2. Unsupervised Learning\n\nUnsupervised learning is a part of machine learning that uncovers patterns in data without knowing the outcomes beforehand. For instance, think of it like sorting customers based on how they spend money. Using algorithms, it identifies similarities in spending habits, creating groups of customers with similar behaviors. This helps businesses understand their customers better and tailor strategies accordingly.\n\n**Examples:**\n\n1.  **K-Means Clustering** involves organizing customers into groups according to their spending habits.\n\n2.  **Principal Component Analysis (PCA)** reduces data complexity while preserving crucial information.\n\n3.  **Hierarchical Clustering** divides a market into distinct customer segments based on purchasing behaviors.\n\n4.  **Association Rule Mining** identifies connections between items in transaction data, like items in a grocery purchase.\n\nNow, let's explore Unsupervised Learning through an example of Hierarchical Clustering.\n\n```{python}\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.datasets import load_iris\nfrom scipy.cluster.hierarchy import dendrogram, linkage\nfrom sklearn.preprocessing import StandardScaler\n\n# Load the Iris dataset\niris = load_iris()\ndata = iris.data\ntarget = iris.target\n\n# Standardize the features for better clustering results\nscaler = StandardScaler()\ndata_scaled = scaler.fit_transform(data)\n\n# Perform hierarchical clustering\nlinked = linkage(data_scaled, 'ward')  # Using 'ward' method for linkage\n\n# Visualize the dendrogram with improved x-label orientation\nplt.figure(figsize=(12, 8))\ndendrogram(linked, orientation='top', distance_sort='descending', show_leaf_counts=True, labels=iris.target_names[target], leaf_rotation=45.)\nplt.title('Hierarchical Clustering Dendrogram (Iris Dataset)')\nplt.xlabel('Species')\nplt.ylabel('Cluster Distance')\nplt.show()\n```\n\n### 3. Reinforcement Learning\n\nReinforcement learning falls under the category of machine learning, where the algorithm learns through practical experience. The algorithm is provided with feedback in the form of rewards or penalties based on its actions, utilizing this information to enhance its performance progressively. For example, one could employ a reinforcement learning algorithm to guide a robot in mastering the navigation through a maze.\n\n**Examples:**\n\n1.  **Game Playing** --- Instructing an agent to engage in chess or Go, rewarding commendable moves and penalizing undesirable ones.\n\n2.  **Robotics** --- Guiding a robot to traverse an environment and execute assigned tasks.\n\n3.  **Stock Trading** --- Equipping an agent to formulate investment choices grounded in stock market data.\n\n4.  **Autonomous Driving** --- Empowering an agent to make determinations on steering, acceleration, and braking in response to road conditions.\n\nNow, let's see an example of Reinforcement Learning: Q-Learning.\n\n```{python}\nimport numpy as np\nimport random\n\n# Define the states\nstates = [0, 1, 2, 3, 4, 5]\n\n# Define the actions\nactions = [0, 1, 2, 3]\n\n# Define the rewards\nrewards = np.array([[0, 1, 0, 0], [1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 0], [1, 0, 0, 0], [0, 0, 0, 0]])\n\n# Define the Q-Table\nQ = np.zeros((6, 4))\n\n# Define the learning rate\nlr = 0.8\n\n# Define the discount factor\ny = 0.95\n\n# Define the number of episodes\nepisodes = 1000\n\nfor i in range(episodes):\n    # Choose a random state\n    state = random.choice(states)\n    while state != 5:\n        # Choose a random action\n        action = random.choice(actions)\n        # Update the Q-Table\n        Q[state, action] = Q[state, action] + lr * (rewards[state, action] + y * np.max(Q[state + 1, :]) - Q[state, action])\n        state = state + 1\n\n# The final Q-Table\nprint(Q)\n```\n\nAnother Example,\\\n\n```{python}\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import FormatStrFormatter\n\ncolors = ['#2ca02c', '#ff7f0e', '#d62728']\nmarkers = ['o', 'd', '^']\n\ngamma = 0.5\nalpha = 0.3\nn = 4\nr_list = np.array([-2., 4., 1.])\nepochs = 25\nq_original = [0, 0, 0]\n\ntrue_q = np.zeros(n - 1)\ncur = 0\nfor j in range(len(true_q) - 1, -1, -1):\n    true_q[j] = r_list[j] + gamma * cur\n    cur = true_q[j]\n\nq_table = np.zeros((epochs, n))\n\nfor j in range(n - 1):\n    q_table[0, j] = q_original[j]\n\nfor x0 in range(1, epochs):\n    for x1 in range(n - 1):\n        learned = r_list[x1] + gamma * q_table[x0 - 1, x1 + 1] - q_table[x0 - 1, x1]\n        q_table[x0, x1] = q_table[x0 - 1, x1] + alpha * learned\n\nfig, ax = plt.subplots(1, 1, figsize=(5, 3), dpi=200)\nfor j in range(n - 1):\n    ax.plot(np.arange(epochs), q_table[:, j],\n            marker=markers[j], markersize=6,\n            alpha=0.7, color=colors[j], linestyle='-',\n            label=f'$Q$' + f'(s{j + 1})')\n    ax.axhline(y=true_q[j], color=colors[j], linestyle='--')\nax.xaxis.set_major_formatter(FormatStrFormatter('%.0f'))\nax.set_ylabel('Q-values')\nax.set_xlabel('Episode')\nax.set_title(r'$\\gamma = $' + f'{gamma}' + r', $\\alpha =$' + f'{alpha}')\nplt.legend(loc='best')\nplt.tight_layout()\nplt.show()\n```\n\nThe code simulates Q-learning, a reinforcement learning algorithm, to update Q-values for different states over multiple episodes. It visualizes the convergence of Q-values towards the true Q-values (computed based on provided rewards and a discount factor) using a simple example with three states. The plot shows the Q-values' evolution across episodes, indicating the algorithm's learning process.\n\n-   gamma and alpha are hyperparameters controlling the discount factor and learning rate, respectively.\n\n-   n represents the number of states, and r_list contains the rewards associated with each state transition.\n\n-   The code iteratively updates Q-values based on the Q-learning update rule and visualizes the convergence process in a plot.\n\n## **Conclusion:**\n\nThere are some Python tools that make it easy to start doing machine learning. Examples include scikit-learn, TensorFlow, and PyTorch.\n\nThese tools come with lots of pre-made programs and features to prepare and look at data. They also have good guides and lessons, which are helpful for beginners.\n\nTo be good at machine learning, it's important to know some stats and math basics. It also helps if you've worked with big sets of data before and know some basic computer programming.\n\nOne big part of machine learning is checking how good your model is. We use things like accuracy and precision to measure this. It's important to understand these measures and pick the right one for your job.\n\nPython has lots of tools to make starting with machine learning easy. The field is always changing, with new things coming out. If you're just starting or have been doing this for a while, there's always something new to learn in machine learning.\n\nTo wrap it up, machine learning is a strong tool for solving different problems, like recognizing pictures or understanding language. It keeps changing, so it's important to keep up with what's new in the field.\\\n","srcMarkdownNoYaml":"\n\n## What is Machine Learning?\n\nMachine learning is a branch of artificial intelligence that focuses on creating algorithms and statistical models for making predictions using data.\n\n-   The fundamental procedure involves the extensive training of a model using a well-defined dataset, where the model learns intricate patterns and relationships within the provided information. This training phase is crucial, as it equips the model with the ability to generalize its acquired knowledge and apply it to new, unseen data, thereby facilitating accurate predictions.\n\n-   There are different types of ways these computer models can learn. In one method called supervised learning, the computer learns from examples where we already know the answers. In another method called unsupervised learning, it figures out patterns and relationships from data without having specific answers given to it. There's also semi-supervised learning, which is a mix of both, and reinforcement learning, where the computer learns by trying things out and getting feedback.\n\n-   So, machine learning is like giving computers the ability to learn from experience and data to make smart predictions.\n\n## Machine Learning Applications:\n\nMachine learning plays an important role in various industries including, healthcare, engineering finance etc.\n\nExamples of machine learning applications are given below,\n\n1.  **Fraud detection:** Employing machine learning algorithms aids in identifying fraudulent transactions through the analysis of patterns within transaction data.\n\n2.  **Image classification:** Machine learning algorithms can be specifically trained to categorize images based on their content, performing tasks like recognizing objects or individuals in photos.\n\n3.  **Predictive maintenance:** Leveraging machine learning algorithms enables the prediction of equipment failures, facilitating proactive maintenance and minimizing downtime.\n\n4.  **Recommender systems:** Machine learning algorithms excel in suggesting products or services based on a user's past interactions with a system, enhancing user experience and engagement.\n\n## Classification of Machine Learning\n\nML is generally classified into three main categories.\n\n### 1. Supervised Learning\n\nSupervised learning is like teaching a computer to predict things. For instance, you can use it to guess a house's price based on its size, location, and other details.Supervised learning is like teaching a computer to predict things. For instance, you can use it to guess a house's price based on its size, location, and other details.\n\n**Examples:**\n\n-   [Linear Regression]{.underline} involves forecasting a house's price by considering its square footage.\n\n-   [Logistic Regression]{.underline} is employed to predict the likelihood of an event, like whether a customer will make a purchase.\n\n-   [Decision Trees]{.underline} are used to estimate the probability of loan applicants defaulting based on their financial history.\n\n-   [Random Forest]{.underline} is applied to predict the species of an iris plant based on its physical characteristics.\n\n-   [Naive Bayes]{.underline} is utilized to determine the sentiment of a movie review, classifying it as positive, negative, or neutral.\n\nExample with code for Supervised Learning (Linear Regression)\n\n```{python}\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_diabetes\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\n# Load the Diabetes dataset\ndiabetes = load_diabetes()\ndata = diabetes.data\ntarget = diabetes.target\n\n# Select a single feature (let's use BMI - body mass index)\nX = data[:, np.newaxis, 2]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, target, test_size=0.2, random_state=42)\n\n# Initialize and train the linear regression model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred = model.predict(X_test)\n\n# Calculate Mean Squared Error\nmse = mean_squared_error(y_test, y_pred)\nprint(f'Mean Squared Error: {mse}')\n\n# Visualize the linear regression line\nplt.figure(figsize=(10, 6))\nplt.scatter(X_test.flatten(), y_test, label='Actual Values')\nplt.plot(X_test.flatten(), y_pred, color='red', linewidth=2, label='Linear Regression Line')\nplt.title('Linear Regression Example (Diabetes Dataset)')\nplt.xlabel('Body Mass Index (BMI)')\nplt.ylabel('Diabetes Progression')\nplt.legend()\nplt.show()\n```\n\n### 2. Unsupervised Learning\n\nUnsupervised learning is a part of machine learning that uncovers patterns in data without knowing the outcomes beforehand. For instance, think of it like sorting customers based on how they spend money. Using algorithms, it identifies similarities in spending habits, creating groups of customers with similar behaviors. This helps businesses understand their customers better and tailor strategies accordingly.\n\n**Examples:**\n\n1.  **K-Means Clustering** involves organizing customers into groups according to their spending habits.\n\n2.  **Principal Component Analysis (PCA)** reduces data complexity while preserving crucial information.\n\n3.  **Hierarchical Clustering** divides a market into distinct customer segments based on purchasing behaviors.\n\n4.  **Association Rule Mining** identifies connections between items in transaction data, like items in a grocery purchase.\n\nNow, let's explore Unsupervised Learning through an example of Hierarchical Clustering.\n\n```{python}\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.datasets import load_iris\nfrom scipy.cluster.hierarchy import dendrogram, linkage\nfrom sklearn.preprocessing import StandardScaler\n\n# Load the Iris dataset\niris = load_iris()\ndata = iris.data\ntarget = iris.target\n\n# Standardize the features for better clustering results\nscaler = StandardScaler()\ndata_scaled = scaler.fit_transform(data)\n\n# Perform hierarchical clustering\nlinked = linkage(data_scaled, 'ward')  # Using 'ward' method for linkage\n\n# Visualize the dendrogram with improved x-label orientation\nplt.figure(figsize=(12, 8))\ndendrogram(linked, orientation='top', distance_sort='descending', show_leaf_counts=True, labels=iris.target_names[target], leaf_rotation=45.)\nplt.title('Hierarchical Clustering Dendrogram (Iris Dataset)')\nplt.xlabel('Species')\nplt.ylabel('Cluster Distance')\nplt.show()\n```\n\n### 3. Reinforcement Learning\n\nReinforcement learning falls under the category of machine learning, where the algorithm learns through practical experience. The algorithm is provided with feedback in the form of rewards or penalties based on its actions, utilizing this information to enhance its performance progressively. For example, one could employ a reinforcement learning algorithm to guide a robot in mastering the navigation through a maze.\n\n**Examples:**\n\n1.  **Game Playing** --- Instructing an agent to engage in chess or Go, rewarding commendable moves and penalizing undesirable ones.\n\n2.  **Robotics** --- Guiding a robot to traverse an environment and execute assigned tasks.\n\n3.  **Stock Trading** --- Equipping an agent to formulate investment choices grounded in stock market data.\n\n4.  **Autonomous Driving** --- Empowering an agent to make determinations on steering, acceleration, and braking in response to road conditions.\n\nNow, let's see an example of Reinforcement Learning: Q-Learning.\n\n```{python}\nimport numpy as np\nimport random\n\n# Define the states\nstates = [0, 1, 2, 3, 4, 5]\n\n# Define the actions\nactions = [0, 1, 2, 3]\n\n# Define the rewards\nrewards = np.array([[0, 1, 0, 0], [1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 0], [1, 0, 0, 0], [0, 0, 0, 0]])\n\n# Define the Q-Table\nQ = np.zeros((6, 4))\n\n# Define the learning rate\nlr = 0.8\n\n# Define the discount factor\ny = 0.95\n\n# Define the number of episodes\nepisodes = 1000\n\nfor i in range(episodes):\n    # Choose a random state\n    state = random.choice(states)\n    while state != 5:\n        # Choose a random action\n        action = random.choice(actions)\n        # Update the Q-Table\n        Q[state, action] = Q[state, action] + lr * (rewards[state, action] + y * np.max(Q[state + 1, :]) - Q[state, action])\n        state = state + 1\n\n# The final Q-Table\nprint(Q)\n```\n\nAnother Example,\\\n\n```{python}\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import FormatStrFormatter\n\ncolors = ['#2ca02c', '#ff7f0e', '#d62728']\nmarkers = ['o', 'd', '^']\n\ngamma = 0.5\nalpha = 0.3\nn = 4\nr_list = np.array([-2., 4., 1.])\nepochs = 25\nq_original = [0, 0, 0]\n\ntrue_q = np.zeros(n - 1)\ncur = 0\nfor j in range(len(true_q) - 1, -1, -1):\n    true_q[j] = r_list[j] + gamma * cur\n    cur = true_q[j]\n\nq_table = np.zeros((epochs, n))\n\nfor j in range(n - 1):\n    q_table[0, j] = q_original[j]\n\nfor x0 in range(1, epochs):\n    for x1 in range(n - 1):\n        learned = r_list[x1] + gamma * q_table[x0 - 1, x1 + 1] - q_table[x0 - 1, x1]\n        q_table[x0, x1] = q_table[x0 - 1, x1] + alpha * learned\n\nfig, ax = plt.subplots(1, 1, figsize=(5, 3), dpi=200)\nfor j in range(n - 1):\n    ax.plot(np.arange(epochs), q_table[:, j],\n            marker=markers[j], markersize=6,\n            alpha=0.7, color=colors[j], linestyle='-',\n            label=f'$Q$' + f'(s{j + 1})')\n    ax.axhline(y=true_q[j], color=colors[j], linestyle='--')\nax.xaxis.set_major_formatter(FormatStrFormatter('%.0f'))\nax.set_ylabel('Q-values')\nax.set_xlabel('Episode')\nax.set_title(r'$\\gamma = $' + f'{gamma}' + r', $\\alpha =$' + f'{alpha}')\nplt.legend(loc='best')\nplt.tight_layout()\nplt.show()\n```\n\nThe code simulates Q-learning, a reinforcement learning algorithm, to update Q-values for different states over multiple episodes. It visualizes the convergence of Q-values towards the true Q-values (computed based on provided rewards and a discount factor) using a simple example with three states. The plot shows the Q-values' evolution across episodes, indicating the algorithm's learning process.\n\n-   gamma and alpha are hyperparameters controlling the discount factor and learning rate, respectively.\n\n-   n represents the number of states, and r_list contains the rewards associated with each state transition.\n\n-   The code iteratively updates Q-values based on the Q-learning update rule and visualizes the convergence process in a plot.\n\n## **Conclusion:**\n\nThere are some Python tools that make it easy to start doing machine learning. Examples include scikit-learn, TensorFlow, and PyTorch.\n\nThese tools come with lots of pre-made programs and features to prepare and look at data. They also have good guides and lessons, which are helpful for beginners.\n\nTo be good at machine learning, it's important to know some stats and math basics. It also helps if you've worked with big sets of data before and know some basic computer programming.\n\nOne big part of machine learning is checking how good your model is. We use things like accuracy and precision to measure this. It's important to understand these measures and pick the right one for your job.\n\nPython has lots of tools to make starting with machine learning easy. The field is always changing, with new things coming out. If you're just starting or have been doing this for a while, there's always something new to learn in machine learning.\n\nTo wrap it up, machine learning is a strong tool for solving different problems, like recognizing pictures or understanding language. It keeps changing, so it's important to keep up with what's new in the field.\\\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":"html_document","warning":true,"include":true,"keep-md":false,"keep-ipynb":true,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":true,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"toc-depth":2,"html-math-method":"katex","output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","theme":"flatly","toc-expand":2,"max-width":"1000px","code-summary":"Show the code","title-block-banner":true,"title":"1\\. Machine Learning Introduction","author":"M Mubashar Ashraf","date":"2023-11-25","categories":["Machine Learing Basics"],"image":"ML-Intro.jpg","jupyter":"python3"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}